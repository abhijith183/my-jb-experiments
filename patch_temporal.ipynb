{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70215d34-475b-4c4b-9bef-86af97685b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91835c30-1cdf-4db5-8396-c46d93d67244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "torch_dtype = torch.bfloat16\n",
    "example = \"travel\"\n",
    "patch_layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e6ecf1-eefb-40f0-9813-037743308be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f042b5d3-d33f-4df4-8dfe-b9014f2b311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5244befb19c4d80973b02598b38d2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype = torch_dtype,\n",
    "    cache_dir=\"./hf_cache\"\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d336d4d8-ada7-4185-be41-c41f8edaa695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=\"./hf_cache\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626aeb69-fca2-42a3-bb46-4836a1e47f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCQuestion:\n",
    "    stem: str\n",
    "    options: List[str]\n",
    "    answer_letter: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29150eac-81db-40d2-92c5-914ef8700c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mc_prompt(mcq):\n",
    "    return(\n",
    "        \"you are a precise reasoner. answer with just the option letter.\\n\\n\"\n",
    "        f\"Question: {mcq.stem}\"\n",
    "        \"Options:\\n\" + \"\\n\".join(mcq.options) + \"\\n\"\n",
    "        \"Answer : \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97f169d-66b4-4e7c-8058-87b67458814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerOutputCache:\n",
    "    def __init__(self):\n",
    "        self.by_idx = {}\n",
    "\n",
    "    def save(self, idx, tensor):\n",
    "        self.by_idx[idx] = tensor.detach()\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.by_idx.get(idx, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c85c622-7bdb-499f-b908-26c526da0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_temporal_pair():\n",
    "    clean = MCQuestion(\n",
    "        stem = \"Alice went to paris in 2010. Bob went in 2015. Who travelled earlier?\",\n",
    "        options = [\"A) Alice\", \"B) Bob\"],\n",
    "        answer_letter = \"A\"\n",
    "    )\n",
    "    corrupted = MCQuestion(\n",
    "        stem = \"Alice went to paris in 2010. Bob went in 2015. Who travelled later?\",\n",
    "        options = [\"A) Alice\", \"B) Bob\"],\n",
    "        answer_letter = \"B\"\n",
    "    )\n",
    "\n",
    "    return clean, corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bbe8405-e1f3-49b1-944e-f4ad81a2cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, corrupted = sample_temporal_pair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e661f97d-3588-4b48-bf69-0c15b7eab8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [opt.split(\")\")[0] for opt in [o.strip() for o in clean.options]]\n",
    "correct_idx = letters.index(clean.answer_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06070d84-17ae-4166-b74a-7b21073dcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prompt = format_mc_prompt(clean)\n",
    "clean_cache = LayerOutputCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91c01de-442a-4b39-b470-a232d93f7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "\n",
    "for i, layer in enumerate(model.model.layers):\n",
    "    def make_hook(i_):\n",
    "        def hook(module, inputs, output):\n",
    "            global clean_cache\n",
    "            clean_cache.save(i_, output)\n",
    "            return output\n",
    "        return hook\n",
    "    handles.append(layer.register_forward_hook(make_hook(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b59d07d-3e34-44c3-80e7-c0ddb1c04fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_hooks = handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef653270-3e0a-4e5f-9b42-5722d1254594",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer(clean_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(\n",
    "        **enc,\n",
    "        use_cache= True,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1524864-9a36-4c1e-8fe3-7816c0e5bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = out.logits[:, -1, :]\n",
    "letter_ids = torch.tensor(\n",
    "    [tokenizer.encode(l, add_special_tokens=False)[0] for l in letters],\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb7acae-66be-49b9-a597-8f481277b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits = logits[0, letter_ids]\n",
    "clean_info = {\n",
    "    \"enc\": enc,\n",
    "    \"outputs\": out,\n",
    "    \"letter_ids\": letter_ids,\n",
    "    \"logits\": logits,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2e4752c-6f56-45ba-8e14-f7b3e6a81f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in clean_hooks:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efaf659-0794-43c5-9fe8-724b521c27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_prompt = format_mc_prompt(corrupted)\n",
    "\n",
    "enc1 = tokenizer(corrupt_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(\n",
    "        **enc1,\n",
    "        use_cache= True,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f351718b-cabc-4777-afa2-24be3a0be848",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = out.logits[:, -1, :]\n",
    "letter_ids = torch.tensor(\n",
    "    [tokenizer.encode(l, add_special_tokens=False)[0] for l in letters],\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "417b1416-74cf-4e93-8ddb-a7dc4b880071",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_logits = logits[0, letter_ids]\n",
    "corrupt_info = {\n",
    "    \"enc\": enc,\n",
    "    \"outputs\": out,\n",
    "    \"letter_ids\": letter_ids,\n",
    "    \"logits\": logits,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8b023a-2848-4002-89b0-49aea1f34891",
   "metadata": {},
   "outputs": [],
   "source": [
    "others = torch.cat([corrupt_logits[:correct_idx], corrupt_logits[correct_idx+1:]], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ec6532-6ae3-44fb-8165-47de3bbda6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_margin = (corrupt_logits[correct_idx] - others.mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e21e593e-02ed-4724-8666-dfc859798a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = {\n",
    "    \"letters\": letters,\n",
    "    \"correct_idx\":correct_idx,\n",
    "    \"clean\":dict(prompt=clean_prompt, logits=clean_logits, info=clean_info, cache=clean_cache),\n",
    "    \"corrupt\":dict(prompt=corrupt_prompt, logits=corrupt_logits, info=corrupt_info, margin = baseline_margin),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54c88096-ea35-4251-b245-cce0693bb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = run[\"letters\"]\n",
    "correct_idx = run[\"correct_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c99b995-6e97-4d2e-8c02-27ac27bac912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'letters': ['A', 'B'],\n",
       " 'correct_idx': 0,\n",
       " 'clean': {'prompt': 'you are a precise reasoner. answer with just the option letter.\\n\\nQuestion: Alice went to paris in 2010. Bob went in 2015. Who travelled earlier?Options:\\nA) Alice\\nB) Bob\\nAnswer : ',\n",
       "  'logits': tensor([14.0625,  7.4375], device='cuda:0', dtype=torch.bfloat16),\n",
       "  'info': {'enc': {'input_ids': tensor([[    1,   368,   460,   264, 17008,  2611,   263, 28723,  4372,   395,\n",
       "              776,   272,  3551,  5498, 28723,    13,    13, 24994, 28747, 14003,\n",
       "             2068,   298,   940,   278,   297, 28705, 28750, 28734, 28740, 28734,\n",
       "            28723,  7409,  2068,   297, 28705, 28750, 28734, 28740, 28782, 28723,\n",
       "             6526,  6834,  6099,  5585, 28804,  4018, 28747,    13, 28741, 28731,\n",
       "            14003,    13, 28760, 28731,  7409,    13,  2820, 16981,   714, 28705]],\n",
       "          device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "   'outputs': CausalLMOutputWithPast(loss=None, logits=tensor([[[ -4.6562,  -4.4375,  -0.0757,  ...,  -3.4688,  -2.5156,  -3.0625],\n",
       "            [ -7.1250,  -6.9375,   4.5938,  ...,  -8.5625,  -6.4062,  -5.5625],\n",
       "            [ -6.4375,  -6.5000,   4.1562,  ...,  -8.1250,  -6.0625,  -6.2500],\n",
       "            ...,\n",
       "            [ -9.5625,  -9.1875,   8.5625,  ...,  -7.9688,  -7.6562,  -7.3438],\n",
       "            [ -9.9375, -10.0000,   9.0625,  ...,  -7.7500,  -8.4375,  -6.5938],\n",
       "            [ -9.5625,  -9.3750,   6.5625,  ...,  -5.5312,  -8.1875,  -4.4375]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer]), hidden_states=(tensor([[[-4.3945e-03, -3.0708e-04, -5.6763e-03,  ..., -2.3270e-04,\n",
       "             -2.1057e-03,  2.1553e-04],\n",
       "            [ 2.8253e-05,  3.2997e-04,  2.9564e-04,  ..., -2.7771e-03,\n",
       "              1.9455e-03, -6.1035e-04],\n",
       "            [ 2.7847e-04, -4.1771e-04, -2.1820e-03,  ..., -1.2054e-03,\n",
       "             -8.8882e-04, -1.5335e-03],\n",
       "            ...,\n",
       "            [ 1.0300e-03, -1.7395e-03,  3.0060e-03,  ...,  5.0659e-03,\n",
       "              7.1335e-04,  2.1973e-03],\n",
       "            [ 3.9673e-03, -3.3569e-03, -1.7700e-03,  ...,  3.4142e-04,\n",
       "              3.6926e-03, -1.5106e-03],\n",
       "            [-1.2054e-03,  9.6130e-04,  3.7909e-05,  ...,  4.5204e-04,\n",
       "             -6.0654e-04,  2.1973e-03]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0008,  0.0033, -0.0630,  ..., -0.0002, -0.0001,  0.0040],\n",
       "            [ 0.0097,  0.0031,  0.0048,  ...,  0.0021, -0.0030, -0.0023],\n",
       "            [ 0.0105,  0.0058,  0.0078,  ..., -0.0045, -0.0027, -0.0047],\n",
       "            ...,\n",
       "            [ 0.0016, -0.0062,  0.0062,  ...,  0.0112,  0.0024, -0.0057],\n",
       "            [ 0.0030, -0.0010,  0.0008,  ...,  0.0009,  0.0049, -0.0019],\n",
       "            [-0.0038,  0.0024,  0.0001,  ...,  0.0018, -0.0011,  0.0032]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-5.9570e-02,  1.9727e-01, -5.4199e-02,  ..., -2.7832e-02,\n",
       "             -3.4180e-02,  7.6660e-02],\n",
       "            [ 5.4321e-03, -4.4250e-04,  8.4839e-03,  ...,  2.9755e-03,\n",
       "              7.9346e-04, -1.6846e-02],\n",
       "            [ 1.1108e-02,  8.5449e-04,  1.1719e-02,  ..., -1.4099e-02,\n",
       "              3.6621e-03, -5.8289e-03],\n",
       "            ...,\n",
       "            [ 1.1047e-02, -1.5869e-02,  1.2695e-02,  ...,  4.0894e-03,\n",
       "             -1.3046e-03, -7.2021e-03],\n",
       "            [ 6.7749e-03,  2.5330e-03, -1.6861e-03,  ..., -5.7373e-03,\n",
       "              3.0518e-05, -1.7395e-03],\n",
       "            [ 2.2278e-03,  1.1658e-02, -1.4496e-03,  ..., -5.9509e-04,\n",
       "             -1.3123e-03,  5.6458e-03]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0608,  0.1973, -0.0544,  ..., -0.0284, -0.0337,  0.0752],\n",
       "            [-0.0007, -0.0020,  0.0140,  ...,  0.0039,  0.0009, -0.0190],\n",
       "            [ 0.0088, -0.0067,  0.0154,  ..., -0.0242,  0.0014, -0.0121],\n",
       "            ...,\n",
       "            [ 0.0022, -0.0168,  0.0192,  ...,  0.0086, -0.0026, -0.0098],\n",
       "            [ 0.0183, -0.0005, -0.0115,  ..., -0.0116, -0.0022, -0.0096],\n",
       "            [-0.0020,  0.0167, -0.0049,  ..., -0.0022, -0.0056,  0.0103]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0635,  0.1963, -0.0549,  ..., -0.0293, -0.0311,  0.0757],\n",
       "            [-0.0081, -0.0004,  0.0127,  ...,  0.0003,  0.0098, -0.0266],\n",
       "            [ 0.0300, -0.0027,  0.0151,  ..., -0.0247,  0.0069, -0.0104],\n",
       "            ...,\n",
       "            [ 0.0034, -0.0203,  0.0139,  ...,  0.0074,  0.0051, -0.0134],\n",
       "            [ 0.0219, -0.0005, -0.0250,  ..., -0.0171,  0.0044, -0.0199],\n",
       "            [-0.0036,  0.0089, -0.0094,  ...,  0.0098, -0.0053,  0.0097]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0625,  0.1914, -0.0562,  ..., -0.0332, -0.0303,  0.0728],\n",
       "            [ 0.0145, -0.0015,  0.0055,  ...,  0.0011,  0.0134, -0.0361],\n",
       "            [ 0.0256,  0.0031,  0.0139,  ..., -0.0299,  0.0071, -0.0050],\n",
       "            ...,\n",
       "            [-0.0238, -0.0103, -0.0118,  ...,  0.0123,  0.0082, -0.0322],\n",
       "            [ 0.0138, -0.0167, -0.0383,  ..., -0.0221, -0.0056, -0.0113],\n",
       "            [ 0.0004,  0.0183, -0.0127,  ...,  0.0150, -0.0137,  0.0110]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0635,  0.1924, -0.0610,  ..., -0.0356, -0.0266,  0.0737],\n",
       "            [ 0.0243, -0.0100,  0.0076,  ...,  0.0178,  0.0205, -0.0299],\n",
       "            [ 0.0311, -0.0065,  0.0211,  ..., -0.0223, -0.0014,  0.0076],\n",
       "            ...,\n",
       "            [-0.0050, -0.0291,  0.0157,  ...,  0.0205,  0.0111, -0.0508],\n",
       "            [ 0.0352, -0.0381, -0.0299,  ..., -0.0144,  0.0167, -0.0081],\n",
       "            [-0.0010,  0.0175,  0.0030,  ...,  0.0200, -0.0153, -0.0057]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0645,  0.1924, -0.0583,  ..., -0.0376, -0.0232,  0.0713],\n",
       "            [ 0.0537, -0.0019,  0.0023,  ...,  0.0352,  0.0410, -0.0383],\n",
       "            [ 0.0369, -0.0234,  0.0227,  ..., -0.0247,  0.0195, -0.0030],\n",
       "            ...,\n",
       "            [ 0.0156, -0.0361, -0.0175,  ...,  0.0408,  0.0137, -0.0317],\n",
       "            [ 0.0393, -0.0396, -0.0422,  ..., -0.0118,  0.0012, -0.0159],\n",
       "            [ 0.0201,  0.0154, -0.0166,  ...,  0.0201, -0.0106,  0.0034]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0713,  0.2100, -0.0583,  ..., -0.0432, -0.0251,  0.0698],\n",
       "            [ 0.0630,  0.0112,  0.0054,  ...,  0.0272,  0.0312, -0.0315],\n",
       "            [ 0.0300, -0.0239,  0.0420,  ..., -0.0378,  0.0276,  0.0010],\n",
       "            ...,\n",
       "            [ 0.0277, -0.0474, -0.0304,  ...,  0.0527,  0.0198, -0.0452],\n",
       "            [ 0.0295, -0.0356, -0.0337,  ...,  0.0204, -0.0045, -0.0258],\n",
       "            [ 0.0021,  0.0220, -0.0190,  ...,  0.0309, -0.0105, -0.0200]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-6.7383e-02,  2.1289e-01, -5.5908e-02,  ..., -4.7119e-02,\n",
       "             -2.6367e-02,  6.7871e-02],\n",
       "            [ 7.0801e-02, -1.0681e-02, -2.1362e-04,  ...,  1.8677e-02,\n",
       "              1.2207e-04, -4.7119e-02],\n",
       "            [ 1.9531e-02, -4.4434e-02,  3.0518e-02,  ..., -3.4668e-02,\n",
       "              9.7656e-03, -7.6294e-03],\n",
       "            ...,\n",
       "            [ 5.7373e-02, -6.1035e-02, -2.7954e-02,  ...,  7.1777e-02,\n",
       "              2.1851e-02, -3.6621e-02],\n",
       "            [ 2.7344e-02, -7.3242e-03, -2.0752e-02,  ...,  3.2227e-02,\n",
       "             -8.2397e-03, -9.8267e-03],\n",
       "            [-8.5449e-03,  1.3123e-02, -7.4768e-03,  ...,  3.8574e-02,\n",
       "             -1.0193e-02,  3.2227e-02]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0659,  0.2432, -0.0510,  ..., -0.0381, -0.0228,  0.0669],\n",
       "            [ 0.0510,  0.0058, -0.0009,  ...,  0.0344,  0.0034, -0.0552],\n",
       "            [ 0.0266, -0.0405,  0.0188,  ..., -0.0039,  0.0234,  0.0045],\n",
       "            ...,\n",
       "            [ 0.0537, -0.0869, -0.0330,  ...,  0.1211,  0.0067, -0.0322],\n",
       "            [ 0.0195, -0.0342, -0.0359,  ...,  0.1055,  0.0027, -0.0137],\n",
       "            [-0.0074, -0.0125, -0.0176,  ...,  0.0771, -0.0151,  0.0322]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0674,  0.2656, -0.0315,  ..., -0.0278, -0.0143,  0.0674],\n",
       "            [ 0.0525, -0.0011,  0.0134,  ...,  0.0547,  0.0125, -0.0549],\n",
       "            [ 0.0186, -0.0938,  0.0771,  ..., -0.0049, -0.0087, -0.0266],\n",
       "            ...,\n",
       "            [ 0.0771, -0.1289, -0.0031,  ...,  0.1084, -0.0050, -0.0981],\n",
       "            [ 0.0615, -0.0593, -0.0052,  ...,  0.0664,  0.0242, -0.0713],\n",
       "            [-0.0300, -0.0244, -0.0055,  ...,  0.0674, -0.0386,  0.0037]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0752,  0.3105, -0.0427,  ..., -0.0315, -0.0114,  0.0659],\n",
       "            [ 0.0530, -0.0059,  0.0215,  ...,  0.0618,  0.0091, -0.0430],\n",
       "            [ 0.0132, -0.1279,  0.0967,  ..., -0.0244,  0.0065, -0.0181],\n",
       "            ...,\n",
       "            [ 0.0986, -0.1201, -0.0371,  ...,  0.1426, -0.0591, -0.1128],\n",
       "            [-0.0374, -0.0664, -0.0209,  ...,  0.0801,  0.0109, -0.0126],\n",
       "            [-0.0659, -0.0354, -0.0064,  ...,  0.0664, -0.0276,  0.0176]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0806,  0.3379, -0.0366,  ..., -0.0415, -0.0093,  0.0649],\n",
       "            [ 0.0525,  0.0035,  0.0170,  ...,  0.0369,  0.0012, -0.0396],\n",
       "            [ 0.0265, -0.1475,  0.0889,  ..., -0.0239, -0.0454, -0.0654],\n",
       "            ...,\n",
       "            [ 0.1221, -0.1943,  0.0330,  ...,  0.1348, -0.0796, -0.1201],\n",
       "            [-0.0415, -0.1064, -0.0060,  ...,  0.1260,  0.0166, -0.0006],\n",
       "            [-0.0115, -0.0270,  0.0452,  ...,  0.0684, -0.0352, -0.0156]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0854,  0.3652, -0.0334,  ..., -0.0356, -0.0071,  0.0659],\n",
       "            [ 0.0479,  0.0198,  0.0325,  ...,  0.0304, -0.0148, -0.0342],\n",
       "            [ 0.0219, -0.1709,  0.0986,  ..., -0.0420, -0.0654, -0.0771],\n",
       "            ...,\n",
       "            [ 0.1328, -0.1504,  0.0149,  ...,  0.1045, -0.0972, -0.0884],\n",
       "            [-0.0405, -0.1162,  0.0195,  ...,  0.0820,  0.0288,  0.0022],\n",
       "            [-0.0688, -0.0208,  0.0737,  ..., -0.0229, -0.0505, -0.0850]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0718,  0.3867, -0.0420,  ..., -0.0339, -0.0024,  0.0703],\n",
       "            [ 0.0483,  0.0085,  0.0330,  ...,  0.0273, -0.0131, -0.0425],\n",
       "            [ 0.0120, -0.1836,  0.1157,  ..., -0.0679, -0.1084, -0.0547],\n",
       "            ...,\n",
       "            [ 0.1533, -0.2236,  0.1099,  ...,  0.1406, -0.0752, -0.1235],\n",
       "            [-0.0452, -0.1562,  0.0923,  ...,  0.1484, -0.0396, -0.1079],\n",
       "            [-0.1089, -0.0132,  0.1011,  ...,  0.0515, -0.0869, -0.1001]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0732,  0.3672, -0.0452,  ..., -0.0515, -0.0029,  0.0781],\n",
       "            [ 0.0574, -0.0366,  0.0493,  ...,  0.0243, -0.0150, -0.0282],\n",
       "            [-0.0208, -0.1357,  0.1138,  ..., -0.0718, -0.1094, -0.0098],\n",
       "            ...,\n",
       "            [ 0.1465, -0.2002,  0.0693,  ...,  0.1621, -0.0532, -0.1309],\n",
       "            [-0.0654, -0.1348,  0.0854,  ...,  0.1758, -0.0210, -0.1738],\n",
       "            [-0.1211, -0.0322,  0.1670,  ...,  0.0933, -0.0278, -0.1250]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0825,  0.3027, -0.0664,  ..., -0.0693, -0.0068,  0.0781],\n",
       "            [ 0.0522, -0.0258,  0.0464,  ...,  0.0013, -0.0203, -0.0115],\n",
       "            [-0.0654, -0.0732,  0.1504,  ..., -0.1484, -0.1318,  0.0251],\n",
       "            ...,\n",
       "            [ 0.0737, -0.1807,  0.2129,  ...,  0.1543, -0.0522,  0.0469],\n",
       "            [-0.1025,  0.0239,  0.2441,  ...,  0.1426,  0.0386, -0.0398],\n",
       "            [-0.1172,  0.0586,  0.3086,  ...,  0.0420,  0.0874,  0.0093]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0962,  0.3164, -0.0381,  ..., -0.0645, -0.0005,  0.0708],\n",
       "            [ 0.0093,  0.0214,  0.0547,  ..., -0.0400, -0.0603, -0.0635],\n",
       "            [-0.1514, -0.0583,  0.1406,  ..., -0.2852, -0.1748, -0.0620],\n",
       "            ...,\n",
       "            [-0.0791,  0.0068,  0.0234,  ...,  0.1221, -0.0220,  0.1973],\n",
       "            [-0.0938,  0.1250,  0.0464,  ..., -0.0122,  0.0186,  0.0276],\n",
       "            [-0.0908,  0.0737,  0.1904,  ..., -0.1084,  0.0703,  0.1504]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0977,  0.2695, -0.0444,  ..., -0.0615,  0.0035,  0.0742],\n",
       "            [-0.0240, -0.0306,  0.0859,  ..., -0.1582, -0.1045, -0.0376],\n",
       "            [-0.1582, -0.1621,  0.1816,  ..., -0.3945, -0.2539, -0.0928],\n",
       "            ...,\n",
       "            [-0.1514,  0.0078, -0.1562,  ...,  0.0144, -0.0144,  0.3594],\n",
       "            [-0.1025,  0.0444, -0.0781,  ..., -0.0320, -0.0059,  0.1123],\n",
       "            [-0.1143,  0.0188,  0.0996,  ..., -0.1787,  0.0815,  0.1631]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1245,  0.2500, -0.0703,  ..., -0.0452, -0.0278,  0.0583],\n",
       "            [ 0.0066,  0.0222, -0.0024,  ..., -0.1074, -0.1045, -0.0292],\n",
       "            [-0.3047, -0.1855,  0.2080,  ..., -0.4609, -0.1914, -0.1152],\n",
       "            ...,\n",
       "            [-0.1533,  0.2578, -0.2188,  ..., -0.0227,  0.0022,  0.3145],\n",
       "            [ 0.0518,  0.1660, -0.1143,  ..., -0.1089, -0.0398,  0.0493],\n",
       "            [ 0.0688,  0.0996,  0.0425,  ..., -0.2891,  0.0439,  0.1250]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1299,  0.1689, -0.0703,  ..., -0.0503, -0.0481,  0.0669],\n",
       "            [-0.0312, -0.0012, -0.0530,  ..., -0.1182, -0.1934, -0.0159],\n",
       "            [-0.2988, -0.2578,  0.1553,  ..., -0.5352, -0.2656, -0.0903],\n",
       "            ...,\n",
       "            [-0.1089,  0.2676, -0.1592,  ..., -0.0474, -0.0029,  0.3242],\n",
       "            [ 0.1025,  0.1855,  0.0117,  ...,  0.0479,  0.0039,  0.1660],\n",
       "            [ 0.0070,  0.1187,  0.0640,  ..., -0.1680,  0.0310,  0.2227]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1357,  0.1157, -0.0684,  ..., -0.0479, -0.0530,  0.0771],\n",
       "            [-0.0293, -0.0162, -0.1123,  ..., -0.1895, -0.2246, -0.0393],\n",
       "            [-0.3965, -0.1543,  0.1846,  ..., -0.5742, -0.1553, -0.1465],\n",
       "            ...,\n",
       "            [-0.1328,  0.1504, -0.1113,  ..., -0.0791,  0.0135,  0.3828],\n",
       "            [ 0.0781,  0.1113,  0.1050,  ...,  0.0859,  0.0879,  0.1963],\n",
       "            [ 0.0461,  0.0649,  0.0708,  ..., -0.1602,  0.1602,  0.1963]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1436,  0.0645, -0.0625,  ..., -0.0581, -0.0559,  0.1060],\n",
       "            [-0.0393, -0.0708, -0.1309,  ..., -0.2266, -0.2480, -0.0474],\n",
       "            [-0.4395, -0.1348,  0.3516,  ..., -0.5469, -0.2080, -0.1699],\n",
       "            ...,\n",
       "            [-0.1875,  0.1562, -0.0986,  ..., -0.1143,  0.1426,  0.3809],\n",
       "            [ 0.0244,  0.0552,  0.0923,  ...,  0.0493,  0.1982,  0.1592],\n",
       "            [ 0.0762,  0.0479,  0.0825,  ..., -0.1650,  0.1318,  0.0508]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1523,  0.0574, -0.0732,  ..., -0.0674, -0.0820,  0.1250],\n",
       "            [-0.0889, -0.0913, -0.0991,  ..., -0.2285, -0.2617, -0.0322],\n",
       "            [-0.5078, -0.0654,  0.4062,  ..., -0.5234, -0.1973, -0.0552],\n",
       "            ...,\n",
       "            [-0.1943,  0.2344, -0.0359,  ..., -0.0854,  0.0674,  0.3633],\n",
       "            [ 0.0093,  0.0942,  0.1797,  ...,  0.0527,  0.1934,  0.1172],\n",
       "            [ 0.0688,  0.0256,  0.1846,  ..., -0.1914,  0.1543, -0.0820]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1523,  0.0459, -0.0596,  ..., -0.0771, -0.0957,  0.1455],\n",
       "            [-0.0513, -0.0757, -0.0913,  ..., -0.2617, -0.3516, -0.0137],\n",
       "            [-0.3516,  0.0122,  0.3750,  ..., -0.5156, -0.2637, -0.0674],\n",
       "            ...,\n",
       "            [-0.3125,  0.1895,  0.1318,  ..., -0.0757,  0.1240,  0.3281],\n",
       "            [ 0.0437,  0.1025,  0.2266,  ...,  0.1289,  0.0112,  0.1826],\n",
       "            [ 0.1650,  0.0869,  0.2100,  ..., -0.2314,  0.1025, -0.0981]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1484,  0.0588, -0.0540,  ..., -0.0884, -0.0967,  0.1445],\n",
       "            [-0.0718, -0.0552, -0.0928,  ..., -0.2754, -0.3555, -0.0413],\n",
       "            [-0.3887,  0.1650,  0.4746,  ..., -0.5078, -0.3379, -0.0850],\n",
       "            ...,\n",
       "            [-0.2578,  0.2393,  0.2285,  ..., -0.1855,  0.1484,  0.3691],\n",
       "            [-0.0012,  0.2578,  0.2168,  ...,  0.1133, -0.0452,  0.1055],\n",
       "            [ 0.1680,  0.3906,  0.3438,  ..., -0.3008,  0.2930, -0.2109]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1387,  0.0635, -0.0454,  ..., -0.1289, -0.0850,  0.1465],\n",
       "            [-0.0259, -0.0859, -0.1641,  ..., -0.2773, -0.3906,  0.0271],\n",
       "            [-0.3359,  0.1221,  0.4375,  ..., -0.5508, -0.3379,  0.0156],\n",
       "            ...,\n",
       "            [-0.2793,  0.2363,  0.2852,  ..., -0.1289,  0.1973,  0.3418],\n",
       "            [-0.0513,  0.3359,  0.2188,  ...,  0.1084,  0.0398,  0.1367],\n",
       "            [ 0.1436,  0.4805,  0.3789,  ..., -0.3594,  0.3867, -0.1338]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1099,  0.0840, -0.0481,  ..., -0.1406, -0.0840,  0.1572],\n",
       "            [ 0.0139, -0.0217, -0.1699,  ..., -0.4082, -0.3906, -0.0266],\n",
       "            [-0.5078,  0.4219,  0.3516,  ..., -0.4160, -0.1846,  0.1367],\n",
       "            ...,\n",
       "            [-0.1992,  0.1455,  0.2314,  ..., -0.0049,  0.1973,  0.3828],\n",
       "            [ 0.0732,  0.3027,  0.1758,  ...,  0.0559,  0.0155,  0.1050],\n",
       "            [ 0.1641,  0.4062,  0.4219,  ..., -0.2930,  0.4043, -0.1699]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1455,  0.1030, -0.0532,  ..., -0.2178, -0.1533,  0.1143],\n",
       "            [-0.0129,  0.0369, -0.2578,  ..., -0.3477, -0.4355,  0.0061],\n",
       "            [-0.6719,  0.4766,  0.4512,  ..., -0.2773, -0.1270,  0.0244],\n",
       "            ...,\n",
       "            [-0.1836,  0.1494,  0.4102,  ...,  0.1055,  0.1758,  0.5039],\n",
       "            [-0.1108,  0.1338,  0.3770,  ...,  0.3359, -0.0112,  0.0549],\n",
       "            [-0.1094,  0.4004,  0.4766,  ...,  0.0098,  0.1826, -0.1426]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.3945,  0.0771, -0.2207,  ..., -0.6953, -0.4609,  0.1123],\n",
       "            [ 0.0422, -0.0488, -0.3281,  ..., -0.4531, -0.4648,  0.0146],\n",
       "            [-0.6914,  0.4883,  0.4434,  ..., -0.3945, -0.2051,  0.1025],\n",
       "            ...,\n",
       "            [-0.2617,  0.4609,  0.4668,  ..., -0.0317, -0.1084,  0.4766],\n",
       "            [-0.1504,  0.3926,  0.3086,  ...,  0.2383,  0.0237, -0.0576],\n",
       "            [-0.0513,  0.5547,  0.5547,  ..., -0.1108,  0.1836, -0.2617]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.7188, -0.1318, -0.7383,  ..., -1.1406, -0.5977,  0.4043],\n",
       "            [-0.0083, -0.1602, -0.4023,  ..., -0.5898, -0.6523, -0.0027],\n",
       "            [-0.4746,  0.5391,  0.3926,  ..., -0.1191, -0.4512,  0.1846],\n",
       "            ...,\n",
       "            [-0.3457,  0.4062,  0.4570,  ..., -0.0168, -0.1328,  0.4707],\n",
       "            [-0.4375,  0.4102,  0.3477,  ...,  0.4062,  0.2656, -0.0654],\n",
       "            [-0.0630,  0.5781,  0.6875,  ..., -0.2480,  0.5547, -0.4512]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-2.0469,  1.9531, -2.1250,  ..., -0.1250, -2.2656,  2.9531],\n",
       "            [ 0.2715,  0.1670, -4.0000,  ..., -5.5625, -5.4688, -0.2988],\n",
       "            [-3.2500,  4.7188,  2.4844,  ..., -0.8750, -2.6406,  1.1562],\n",
       "            ...,\n",
       "            [-1.3438,  4.1250,  3.3594,  ..., -0.0356, -1.7578,  3.0625],\n",
       "            [-2.3125,  6.0625,  2.9531,  ...,  2.8281,  1.9531,  0.1885],\n",
       "            [-0.3301,  4.9375,  3.7812,  ..., -0.1621,  5.9062, -3.9531]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16)), attentions=None),\n",
       "   'letter_ids': tensor([330, 365], device='cuda:0'),\n",
       "   'logits': tensor([[-9.5625, -9.3750,  6.5625,  ..., -5.5312, -8.1875, -4.4375]],\n",
       "          device='cuda:0', dtype=torch.bfloat16)},\n",
       "  'cache': <__main__.LayerOutputCache at 0x14912ea9cc20>},\n",
       " 'corrupt': {'prompt': 'you are a precise reasoner. answer with just the option letter.\\n\\nQuestion: Alice went to paris in 2010. Bob went in 2015. Who travelled later?Options:\\nA) Alice\\nB) Bob\\nAnswer : ',\n",
       "  'logits': tensor([ 9.1875, 12.3125], device='cuda:0', dtype=torch.bfloat16),\n",
       "  'info': {'enc': {'input_ids': tensor([[    1,   368,   460,   264, 17008,  2611,   263, 28723,  4372,   395,\n",
       "              776,   272,  3551,  5498, 28723,    13,    13, 24994, 28747, 14003,\n",
       "             2068,   298,   940,   278,   297, 28705, 28750, 28734, 28740, 28734,\n",
       "            28723,  7409,  2068,   297, 28705, 28750, 28734, 28740, 28782, 28723,\n",
       "             6526,  6834,  6099,  5585, 28804,  4018, 28747,    13, 28741, 28731,\n",
       "            14003,    13, 28760, 28731,  7409,    13,  2820, 16981,   714, 28705]],\n",
       "          device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "   'outputs': CausalLMOutputWithPast(loss=None, logits=tensor([[[-4.6562, -4.4375, -0.0757,  ..., -3.4688, -2.5156, -3.0625],\n",
       "            [-7.1250, -6.9375,  4.5938,  ..., -8.5625, -6.4062, -5.5625],\n",
       "            [-6.4375, -6.5000,  4.1562,  ..., -8.1250, -6.0625, -6.2500],\n",
       "            ...,\n",
       "            [-9.5625, -9.1875,  8.5625,  ..., -7.7812, -7.5000, -7.2812],\n",
       "            [-9.1875, -9.2500,  8.7500,  ..., -6.7812, -7.6875, -6.2812],\n",
       "            [-9.0000, -9.0000,  6.4688,  ..., -4.1875, -6.9688, -4.0938]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer]), hidden_states=(tensor([[[-4.3945e-03, -3.0708e-04, -5.6763e-03,  ..., -2.3270e-04,\n",
       "             -2.1057e-03,  2.1553e-04],\n",
       "            [ 2.8253e-05,  3.2997e-04,  2.9564e-04,  ..., -2.7771e-03,\n",
       "              1.9455e-03, -6.1035e-04],\n",
       "            [ 2.7847e-04, -4.1771e-04, -2.1820e-03,  ..., -1.2054e-03,\n",
       "             -8.8882e-04, -1.5335e-03],\n",
       "            ...,\n",
       "            [ 1.0300e-03, -1.7395e-03,  3.0060e-03,  ...,  5.0659e-03,\n",
       "              7.1335e-04,  2.1973e-03],\n",
       "            [ 3.9673e-03, -3.3569e-03, -1.7700e-03,  ...,  3.4142e-04,\n",
       "              3.6926e-03, -1.5106e-03],\n",
       "            [-1.2054e-03,  9.6130e-04,  3.7909e-05,  ...,  4.5204e-04,\n",
       "             -6.0654e-04,  2.1973e-03]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0008,  0.0033, -0.0630,  ..., -0.0002, -0.0001,  0.0040],\n",
       "            [ 0.0097,  0.0031,  0.0048,  ...,  0.0021, -0.0030, -0.0023],\n",
       "            [ 0.0105,  0.0058,  0.0078,  ..., -0.0045, -0.0027, -0.0047],\n",
       "            ...,\n",
       "            [ 0.0016, -0.0062,  0.0062,  ...,  0.0112,  0.0024, -0.0057],\n",
       "            [ 0.0030, -0.0010,  0.0009,  ...,  0.0009,  0.0048, -0.0019],\n",
       "            [-0.0038,  0.0024,  0.0002,  ...,  0.0018, -0.0012,  0.0033]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-5.9570e-02,  1.9727e-01, -5.4199e-02,  ..., -2.7832e-02,\n",
       "             -3.4180e-02,  7.6660e-02],\n",
       "            [ 5.4321e-03, -4.4250e-04,  8.4839e-03,  ...,  2.9755e-03,\n",
       "              7.9346e-04, -1.6846e-02],\n",
       "            [ 1.1108e-02,  8.5449e-04,  1.1719e-02,  ..., -1.4099e-02,\n",
       "              3.6621e-03, -5.8289e-03],\n",
       "            ...,\n",
       "            [ 1.1169e-02, -1.5747e-02,  1.2817e-02,  ...,  4.1504e-03,\n",
       "             -1.3733e-03, -7.1716e-03],\n",
       "            [ 6.7444e-03,  2.6855e-03, -1.5259e-03,  ..., -5.7068e-03,\n",
       "             -2.2888e-05, -1.5564e-03],\n",
       "            [ 2.3193e-03,  1.1658e-02, -1.5106e-03,  ..., -6.8283e-04,\n",
       "             -1.4114e-03,  5.7068e-03]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0608,  0.1973, -0.0544,  ..., -0.0284, -0.0337,  0.0752],\n",
       "            [-0.0007, -0.0020,  0.0140,  ...,  0.0039,  0.0009, -0.0190],\n",
       "            [ 0.0088, -0.0067,  0.0154,  ..., -0.0242,  0.0014, -0.0121],\n",
       "            ...,\n",
       "            [ 0.0027, -0.0168,  0.0194,  ...,  0.0088, -0.0028, -0.0098],\n",
       "            [ 0.0183, -0.0003, -0.0113,  ..., -0.0115, -0.0021, -0.0095],\n",
       "            [-0.0020,  0.0168, -0.0049,  ..., -0.0022, -0.0056,  0.0103]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0635,  0.1963, -0.0549,  ..., -0.0293, -0.0311,  0.0757],\n",
       "            [-0.0081, -0.0004,  0.0127,  ...,  0.0003,  0.0098, -0.0266],\n",
       "            [ 0.0300, -0.0027,  0.0151,  ..., -0.0247,  0.0069, -0.0104],\n",
       "            ...,\n",
       "            [ 0.0052, -0.0190,  0.0146,  ...,  0.0076,  0.0042, -0.0125],\n",
       "            [ 0.0225, -0.0002, -0.0249,  ..., -0.0166,  0.0038, -0.0195],\n",
       "            [-0.0030,  0.0098, -0.0098,  ...,  0.0098, -0.0054,  0.0103]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0625,  0.1914, -0.0562,  ..., -0.0332, -0.0303,  0.0728],\n",
       "            [ 0.0145, -0.0015,  0.0055,  ...,  0.0011,  0.0134, -0.0361],\n",
       "            [ 0.0256,  0.0031,  0.0139,  ..., -0.0299,  0.0071, -0.0050],\n",
       "            ...,\n",
       "            [-0.0222, -0.0086, -0.0101,  ...,  0.0132,  0.0061, -0.0320],\n",
       "            [ 0.0138, -0.0153, -0.0374,  ..., -0.0209, -0.0071, -0.0103],\n",
       "            [ 0.0011,  0.0197, -0.0118,  ...,  0.0153, -0.0138,  0.0120]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0635,  0.1924, -0.0610,  ..., -0.0356, -0.0266,  0.0737],\n",
       "            [ 0.0243, -0.0100,  0.0076,  ...,  0.0178,  0.0205, -0.0299],\n",
       "            [ 0.0311, -0.0065,  0.0211,  ..., -0.0223, -0.0014,  0.0076],\n",
       "            ...,\n",
       "            [-0.0041, -0.0278,  0.0175,  ...,  0.0220,  0.0090, -0.0505],\n",
       "            [ 0.0337, -0.0366, -0.0288,  ..., -0.0117,  0.0154, -0.0070],\n",
       "            [-0.0029,  0.0194,  0.0024,  ...,  0.0228, -0.0137, -0.0057]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0645,  0.1924, -0.0583,  ..., -0.0376, -0.0232,  0.0713],\n",
       "            [ 0.0537, -0.0019,  0.0023,  ...,  0.0352,  0.0410, -0.0383],\n",
       "            [ 0.0369, -0.0234,  0.0227,  ..., -0.0247,  0.0195, -0.0030],\n",
       "            ...,\n",
       "            [ 0.0151, -0.0352, -0.0165,  ...,  0.0432,  0.0123, -0.0309],\n",
       "            [ 0.0391, -0.0371, -0.0425,  ..., -0.0076,  0.0010, -0.0152],\n",
       "            [ 0.0189,  0.0178, -0.0182,  ...,  0.0228, -0.0057,  0.0049]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0713,  0.2100, -0.0583,  ..., -0.0432, -0.0251,  0.0698],\n",
       "            [ 0.0630,  0.0112,  0.0054,  ...,  0.0272,  0.0312, -0.0315],\n",
       "            [ 0.0300, -0.0239,  0.0420,  ..., -0.0378,  0.0276,  0.0010],\n",
       "            ...,\n",
       "            [ 0.0270, -0.0469, -0.0311,  ...,  0.0571,  0.0203, -0.0425],\n",
       "            [ 0.0289, -0.0337, -0.0332,  ...,  0.0237, -0.0036, -0.0233],\n",
       "            [ 0.0014,  0.0281, -0.0215,  ...,  0.0283, -0.0085, -0.0140]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-6.7383e-02,  2.1289e-01, -5.5908e-02,  ..., -4.7119e-02,\n",
       "             -2.6367e-02,  6.7871e-02],\n",
       "            [ 7.0801e-02, -1.0681e-02, -2.1362e-04,  ...,  1.8677e-02,\n",
       "              1.2207e-04, -4.7119e-02],\n",
       "            [ 1.9531e-02, -4.4434e-02,  3.0518e-02,  ..., -3.4668e-02,\n",
       "              9.7656e-03, -7.6294e-03],\n",
       "            ...,\n",
       "            [ 5.8350e-02, -6.2988e-02, -2.8198e-02,  ...,  7.2754e-02,\n",
       "              2.2461e-02, -3.5400e-02],\n",
       "            [ 2.6611e-02, -7.8125e-03, -2.2217e-02,  ...,  3.0396e-02,\n",
       "             -6.5002e-03, -8.0566e-03],\n",
       "            [-4.7302e-03,  1.8433e-02, -2.4658e-02,  ...,  2.1729e-02,\n",
       "             -9.6436e-03,  3.1738e-02]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0659,  0.2432, -0.0510,  ..., -0.0381, -0.0228,  0.0669],\n",
       "            [ 0.0510,  0.0058, -0.0009,  ...,  0.0344,  0.0034, -0.0552],\n",
       "            [ 0.0266, -0.0405,  0.0188,  ..., -0.0039,  0.0234,  0.0045],\n",
       "            ...,\n",
       "            [ 0.0571, -0.0869, -0.0352,  ...,  0.1230,  0.0074, -0.0303],\n",
       "            [ 0.0229, -0.0352, -0.0371,  ...,  0.1035,  0.0051, -0.0104],\n",
       "            [-0.0047, -0.0143, -0.0356,  ...,  0.0767, -0.0123,  0.0342]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0674,  0.2656, -0.0315,  ..., -0.0278, -0.0143,  0.0674],\n",
       "            [ 0.0525, -0.0011,  0.0134,  ...,  0.0547,  0.0125, -0.0549],\n",
       "            [ 0.0186, -0.0938,  0.0771,  ..., -0.0049, -0.0087, -0.0266],\n",
       "            ...,\n",
       "            [ 0.0820, -0.1260, -0.0078,  ...,  0.1064, -0.0070, -0.0967],\n",
       "            [ 0.0654, -0.0601, -0.0088,  ...,  0.0605,  0.0273, -0.0674],\n",
       "            [-0.0123, -0.0229, -0.0189,  ...,  0.0569, -0.0214,  0.0031]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0752,  0.3105, -0.0427,  ..., -0.0315, -0.0114,  0.0659],\n",
       "            [ 0.0530, -0.0059,  0.0215,  ...,  0.0618,  0.0091, -0.0430],\n",
       "            [ 0.0132, -0.1279,  0.0967,  ..., -0.0244,  0.0065, -0.0181],\n",
       "            ...,\n",
       "            [ 0.1050, -0.1147, -0.0444,  ...,  0.1406, -0.0654, -0.1074],\n",
       "            [-0.0291, -0.0645, -0.0312,  ...,  0.0767,  0.0116, -0.0079],\n",
       "            [-0.0537, -0.0461, -0.0242,  ...,  0.0598, -0.0220,  0.0234]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0806,  0.3379, -0.0366,  ..., -0.0415, -0.0093,  0.0649],\n",
       "            [ 0.0525,  0.0035,  0.0170,  ...,  0.0369,  0.0012, -0.0396],\n",
       "            [ 0.0265, -0.1475,  0.0889,  ..., -0.0239, -0.0454, -0.0654],\n",
       "            ...,\n",
       "            [ 0.1299, -0.1836,  0.0256,  ...,  0.1328, -0.0850, -0.1143],\n",
       "            [-0.0366, -0.1040, -0.0159,  ...,  0.1216,  0.0208,  0.0018],\n",
       "            [ 0.0056, -0.0247,  0.0186,  ...,  0.0693, -0.0310,  0.0283]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0854,  0.3652, -0.0334,  ..., -0.0356, -0.0071,  0.0659],\n",
       "            [ 0.0479,  0.0198,  0.0325,  ...,  0.0304, -0.0148, -0.0342],\n",
       "            [ 0.0219, -0.1709,  0.0986,  ..., -0.0420, -0.0654, -0.0771],\n",
       "            ...,\n",
       "            [ 0.1416, -0.1377,  0.0144,  ...,  0.1016, -0.1089, -0.0859],\n",
       "            [-0.0208, -0.1104,  0.0017,  ...,  0.0713,  0.0272,  0.0109],\n",
       "            [-0.0161, -0.0093,  0.0225,  ..., -0.0195, -0.0444, -0.0052]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0718,  0.3867, -0.0420,  ..., -0.0339, -0.0024,  0.0703],\n",
       "            [ 0.0483,  0.0085,  0.0330,  ...,  0.0273, -0.0131, -0.0425],\n",
       "            [ 0.0120, -0.1836,  0.1157,  ..., -0.0679, -0.1084, -0.0547],\n",
       "            ...,\n",
       "            [ 0.1709, -0.2119,  0.0942,  ...,  0.1357, -0.0820, -0.1191],\n",
       "            [ 0.0449, -0.1436,  0.0474,  ...,  0.1235, -0.0103, -0.0957],\n",
       "            [ 0.0126, -0.0095,  0.0505,  ...,  0.0337, -0.0767, -0.0542]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0732,  0.3672, -0.0452,  ..., -0.0515, -0.0029,  0.0781],\n",
       "            [ 0.0574, -0.0366,  0.0493,  ...,  0.0243, -0.0150, -0.0282],\n",
       "            [-0.0208, -0.1357,  0.1138,  ..., -0.0718, -0.1094, -0.0098],\n",
       "            ...,\n",
       "            [ 0.1699, -0.1816,  0.0583,  ...,  0.1670, -0.0664, -0.1367],\n",
       "            [ 0.0664, -0.0830,  0.0806,  ...,  0.1836, -0.0413, -0.1992],\n",
       "            [ 0.0815,  0.0106,  0.1162,  ...,  0.0771, -0.0498, -0.1484]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0825,  0.3027, -0.0664,  ..., -0.0693, -0.0068,  0.0781],\n",
       "            [ 0.0522, -0.0258,  0.0464,  ...,  0.0013, -0.0203, -0.0115],\n",
       "            [-0.0654, -0.0732,  0.1504,  ..., -0.1484, -0.1318,  0.0251],\n",
       "            ...,\n",
       "            [ 0.1084, -0.1514,  0.2012,  ...,  0.1641, -0.0889,  0.0181],\n",
       "            [ 0.0737,  0.0010,  0.0957,  ...,  0.1982, -0.0732, -0.0889],\n",
       "            [ 0.1699,  0.0249,  0.2285,  ...,  0.0840,  0.0049, -0.0361]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0962,  0.3164, -0.0381,  ..., -0.0645, -0.0005,  0.0708],\n",
       "            [ 0.0093,  0.0214,  0.0547,  ..., -0.0400, -0.0603, -0.0635],\n",
       "            [-0.1514, -0.0583,  0.1406,  ..., -0.2852, -0.1748, -0.0620],\n",
       "            ...,\n",
       "            [-0.0571,  0.0317,  0.0010,  ...,  0.1406, -0.0698,  0.1816],\n",
       "            [ 0.0161,  0.0571, -0.1094,  ...,  0.0967, -0.1260,  0.0703],\n",
       "            [ 0.1113, -0.0156,  0.1191,  ..., -0.0012, -0.0198,  0.1191]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0977,  0.2695, -0.0444,  ..., -0.0615,  0.0035,  0.0742],\n",
       "            [-0.0240, -0.0306,  0.0859,  ..., -0.1582, -0.1045, -0.0376],\n",
       "            [-0.1582, -0.1621,  0.1816,  ..., -0.3945, -0.2539, -0.0928],\n",
       "            ...,\n",
       "            [-0.1357,  0.0234, -0.1650,  ...,  0.0549, -0.0684,  0.3594],\n",
       "            [ 0.0515, -0.0032, -0.1836,  ...,  0.0894, -0.1826,  0.1934],\n",
       "            [ 0.1465, -0.1211, -0.0117,  ...,  0.0073, -0.0635,  0.2402]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1245,  0.2500, -0.0703,  ..., -0.0452, -0.0278,  0.0583],\n",
       "            [ 0.0066,  0.0222, -0.0024,  ..., -0.1074, -0.1045, -0.0292],\n",
       "            [-0.3047, -0.1855,  0.2080,  ..., -0.4609, -0.1914, -0.1152],\n",
       "            ...,\n",
       "            [-0.1055,  0.2891, -0.2168,  ...,  0.0356, -0.0095,  0.3691],\n",
       "            [ 0.1729,  0.0957, -0.1641,  ...,  0.1143, -0.1416,  0.2969],\n",
       "            [ 0.2832, -0.0400, -0.0415,  ...,  0.0364, -0.0588,  0.3496]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1299,  0.1689, -0.0703,  ..., -0.0503, -0.0481,  0.0669],\n",
       "            [-0.0312, -0.0012, -0.0530,  ..., -0.1182, -0.1934, -0.0159],\n",
       "            [-0.2988, -0.2578,  0.1553,  ..., -0.5352, -0.2656, -0.0903],\n",
       "            ...,\n",
       "            [-0.0547,  0.2910, -0.1621,  ...,  0.0049,  0.0039,  0.3672],\n",
       "            [ 0.2734,  0.0918, -0.1074,  ...,  0.1816, -0.0156,  0.3887],\n",
       "            [ 0.3672, -0.0513,  0.0483,  ...,  0.0742,  0.0381,  0.3477]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1357,  0.1157, -0.0684,  ..., -0.0479, -0.0530,  0.0771],\n",
       "            [-0.0293, -0.0162, -0.1123,  ..., -0.1895, -0.2246, -0.0393],\n",
       "            [-0.3965, -0.1543,  0.1846,  ..., -0.5742, -0.1553, -0.1465],\n",
       "            ...,\n",
       "            [-0.0840,  0.1807, -0.1318,  ..., -0.0177,  0.0278,  0.4414],\n",
       "            [ 0.2031,  0.0273,  0.0312,  ...,  0.1006,  0.0449,  0.5117],\n",
       "            [ 0.3730, -0.0776,  0.1396,  ..., -0.0269,  0.0986,  0.4492]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1436,  0.0645, -0.0625,  ..., -0.0581, -0.0559,  0.1060],\n",
       "            [-0.0393, -0.0708, -0.1309,  ..., -0.2266, -0.2480, -0.0474],\n",
       "            [-0.4395, -0.1348,  0.3516,  ..., -0.5469, -0.2080, -0.1699],\n",
       "            ...,\n",
       "            [-0.1191,  0.2031, -0.1279,  ..., -0.0532,  0.1729,  0.4355],\n",
       "            [ 0.2168,  0.0201,  0.0227,  ...,  0.1069,  0.1426,  0.5156],\n",
       "            [ 0.4277, -0.0405,  0.1553,  ..., -0.0271,  0.0776,  0.4258]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1523,  0.0574, -0.0732,  ..., -0.0674, -0.0820,  0.1250],\n",
       "            [-0.0889, -0.0913, -0.0991,  ..., -0.2285, -0.2617, -0.0322],\n",
       "            [-0.5078, -0.0654,  0.4062,  ..., -0.5234, -0.1973, -0.0552],\n",
       "            ...,\n",
       "            [-0.1426,  0.2754, -0.0674,  ..., -0.0237,  0.0918,  0.4082],\n",
       "            [ 0.1943,  0.0693,  0.0942,  ...,  0.1445,  0.1875,  0.4941],\n",
       "            [ 0.3926,  0.0400,  0.2246,  ..., -0.0439,  0.1641,  0.3770]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1523,  0.0459, -0.0596,  ..., -0.0771, -0.0957,  0.1455],\n",
       "            [-0.0513, -0.0757, -0.0913,  ..., -0.2617, -0.3516, -0.0137],\n",
       "            [-0.3516,  0.0122,  0.3750,  ..., -0.5156, -0.2637, -0.0674],\n",
       "            ...,\n",
       "            [-0.2520,  0.2324,  0.0830,  ..., -0.0200,  0.1641,  0.4043],\n",
       "            [ 0.2891,  0.0166,  0.0125,  ...,  0.2305,  0.1270,  0.6328],\n",
       "            [ 0.5000,  0.0664,  0.1885,  ..., -0.0320,  0.2129,  0.4277]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1484,  0.0588, -0.0540,  ..., -0.0884, -0.0967,  0.1445],\n",
       "            [-0.0718, -0.0552, -0.0928,  ..., -0.2754, -0.3555, -0.0413],\n",
       "            [-0.3887,  0.1650,  0.4746,  ..., -0.5078, -0.3379, -0.0850],\n",
       "            ...,\n",
       "            [-0.1924,  0.2578,  0.1592,  ..., -0.1328,  0.1836,  0.4531],\n",
       "            [ 0.2520,  0.1104, -0.0522,  ...,  0.1807,  0.0654,  0.6328],\n",
       "            [ 0.4258,  0.2129,  0.1816,  ..., -0.1309,  0.2695,  0.4102]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1387,  0.0635, -0.0454,  ..., -0.1289, -0.0850,  0.1465],\n",
       "            [-0.0259, -0.0859, -0.1641,  ..., -0.2773, -0.3906,  0.0271],\n",
       "            [-0.3359,  0.1221,  0.4375,  ..., -0.5508, -0.3379,  0.0156],\n",
       "            ...,\n",
       "            [-0.2227,  0.2637,  0.2041,  ..., -0.0850,  0.2168,  0.4219],\n",
       "            [ 0.1914,  0.1235, -0.0209,  ...,  0.2285,  0.1484,  0.6562],\n",
       "            [ 0.3809,  0.2266,  0.2178,  ..., -0.1436,  0.3730,  0.4258]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1099,  0.0840, -0.0481,  ..., -0.1406, -0.0840,  0.1572],\n",
       "            [ 0.0139, -0.0217, -0.1699,  ..., -0.4082, -0.3906, -0.0266],\n",
       "            [-0.5078,  0.4219,  0.3516,  ..., -0.4160, -0.1846,  0.1367],\n",
       "            ...,\n",
       "            [-0.1084,  0.1797,  0.1553,  ...,  0.0371,  0.2227,  0.4824],\n",
       "            [ 0.3555,  0.1377, -0.0581,  ...,  0.1514,  0.1934,  0.6914],\n",
       "            [ 0.5039,  0.1006,  0.2158,  ..., -0.1748,  0.4648,  0.3359]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.1455,  0.1030, -0.0532,  ..., -0.2178, -0.1533,  0.1143],\n",
       "            [-0.0129,  0.0369, -0.2578,  ..., -0.3477, -0.4355,  0.0061],\n",
       "            [-0.6719,  0.4766,  0.4512,  ..., -0.2773, -0.1270,  0.0244],\n",
       "            ...,\n",
       "            [-0.0762,  0.1934,  0.2559,  ...,  0.0986,  0.1748,  0.5469],\n",
       "            [ 0.2383,  0.1670, -0.0381,  ...,  0.0947,  0.2754,  0.5312],\n",
       "            [ 0.3242,  0.2578,  0.2393,  ..., -0.0996,  0.4199,  0.2734]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.3945,  0.0771, -0.2207,  ..., -0.6953, -0.4609,  0.1123],\n",
       "            [ 0.0422, -0.0488, -0.3281,  ..., -0.4531, -0.4648,  0.0146],\n",
       "            [-0.6914,  0.4883,  0.4434,  ..., -0.3945, -0.2051,  0.1025],\n",
       "            ...,\n",
       "            [-0.1216,  0.4980,  0.3516,  ..., -0.0613, -0.1118,  0.5273],\n",
       "            [ 0.2119,  0.4688,  0.0281,  ...,  0.0454,  0.2441,  0.4297],\n",
       "            [ 0.3223,  0.3789,  0.3008,  ..., -0.2168,  0.4375,  0.0869]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.7188, -0.1318, -0.7383,  ..., -1.1406, -0.5977,  0.4043],\n",
       "            [-0.0083, -0.1602, -0.4023,  ..., -0.5898, -0.6523, -0.0027],\n",
       "            [-0.4746,  0.5391,  0.3926,  ..., -0.1191, -0.4512,  0.1846],\n",
       "            ...,\n",
       "            [-0.1875,  0.4863,  0.3223,  ..., -0.0222, -0.1660,  0.5039],\n",
       "            [ 0.1621,  0.4766, -0.0259,  ...,  0.2812,  0.4648,  0.4492],\n",
       "            [ 0.5938,  0.4844,  0.4590,  ..., -0.3262,  0.7969,  0.1025]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16), tensor([[[-2.0469,  1.9531, -2.1250,  ..., -0.1250, -2.2656,  2.9531],\n",
       "            [ 0.2715,  0.1670, -4.0000,  ..., -5.5625, -5.4688, -0.2988],\n",
       "            [-3.2500,  4.7188,  2.4844,  ..., -0.8750, -2.6406,  1.1562],\n",
       "            ...,\n",
       "            [-0.0986,  4.2812,  2.0938,  ..., -0.0500, -2.3438,  3.2031],\n",
       "            [ 2.0938,  3.9688, -0.6211,  ...,  1.8984,  1.7188,  3.2656],\n",
       "            [ 5.3125,  1.5156,  0.7031,  ..., -0.4297,  6.6250, -0.2246]]],\n",
       "          device='cuda:0', dtype=torch.bfloat16)), attentions=None),\n",
       "   'letter_ids': tensor([330, 365], device='cuda:0'),\n",
       "   'logits': tensor([[-9.0000, -9.0000,  6.4688,  ..., -4.1875, -6.9688, -4.0938]],\n",
       "          device='cuda:0', dtype=torch.bfloat16)},\n",
       "  'margin': -3.125}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ae12e0-c11c-422f-b14b-502fa78fa531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean:[14.0625, 7.4375]\n",
      "Corrupt:[9.1875, 12.3125]\n"
     ]
    }
   ],
   "source": [
    "clean_logits = run[\"clean\"][\"logits\"]\n",
    "corrupt_logits = run[\"corrupt\"][\"logits\"]\n",
    "print(f\"Clean:{clean_logits.detach().cpu().tolist()}\")\n",
    "print(f\"Corrupt:{corrupt_logits.detach().cpu().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13d51484-41b6-4d06-8a0c-6951b019d7d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.125\n"
     ]
    }
   ],
   "source": [
    "baseline_margin = run[\"corrupt\"][\"margin\"]\n",
    "\n",
    "print(baseline_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a51e79e-4980-4c70-933f-6dabbf2dfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(model.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8874200c-da6f-4c42-8225-309422294c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_patch = patch_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f305de03-ca61-4e24-9828-713c7eb3cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputReplacementHook:\n",
    "    def __init__(self, layer_idx, replacement):\n",
    "        self.layer_idx = layer_idx\n",
    "        self.replacement = replacement\n",
    "        self.handle = None\n",
    "\n",
    "    def install(self, model):\n",
    "        target_layer = model.model.layers[self.layer_idx]\n",
    "        def hook(module, inputs, output):\n",
    "            if output.shape != self.replacement.shape:\n",
    "                raise ValueError(\"shape error\")\n",
    "\n",
    "            return self.replacement\n",
    "        self.handle = target_layer.register_forward_hook(hook)\n",
    "\n",
    "    def remove(self):\n",
    "        if self.handle is not None:\n",
    "            self.handle.remove()\n",
    "            self.handle = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c597e9db-de36-42bc-bdad-5d019922cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = run[\"letters\"]\n",
    "correct_idx = run[\"correct_idx\"]\n",
    "corrupt_prompt = run[\"corrupt\"][\"prompt\"]\n",
    "clean_cache: LayerOutputCache = run[\"clean\"][\"cache\"]\n",
    "\n",
    "replacement = clean_cache.get(layer_to_patch)\n",
    "hook = OutputReplacementHook(layer_to_patch, replacement)\n",
    "hook.install(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd5327d7-fdc9-49d9-b120-9780ae9b880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anvil/projects/x-cis250308/miniconda/lib/python3.13/site-packages/transformers/utils/generic.py:1005: UserWarning: `output_attentions=True` is not supported with `attn_implementation` other than ['eager', 'eager_paged', 'flex_attention']. Please use `model.set_attn_implementation('eager')` to enable capturing attention outputs.\n",
      "  warnings.warn(\n",
      "`sdpa` attention does not support `output_attentions=True` or `head_mask`. Please set your attention to `eager` if you want any of these features.\n"
     ]
    }
   ],
   "source": [
    "enc3 = tokenizer(corrupt_prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    out = model(\n",
    "        **enc3,\n",
    "        use_cache = True,\n",
    "        output_attentions = True,\n",
    "        output_hidden_states = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25feea90-c51a-4f7d-8f4f-fca3cd4f07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = out.logits[:, -1, :]\n",
    "letter_ids = torch.tensor(\n",
    "    [tokenizer.encode(l, add_special_tokens=False)[0] for l in letters],\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e7c5b0e-c9ee-44d2-a443-fd34e35d8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_logits = logits[0, letter_ids]\n",
    "patched_info = {\n",
    "    \"enc\":enc3,\n",
    "    \"outputs\" : out,\n",
    "    \"letter_ids\": letter_ids,\n",
    "    \"logits\":logits\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd1a7250-4908-48f7-a603-761cef3f7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7c22f18-0db7-4b52-83cc-49cd66e5109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "others = torch.cat(\n",
    "    [patched_logits[:correct_idx], patched_logits[correct_idx+1:]],\n",
    "    dim = 0\n",
    ")\n",
    "l_diff = (patched_logits[correct_idx] - others.mean()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d99adf8f-5647-437c-af16-402d4dbc0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_res = {\n",
    "    \"layer_idx\": layer_to_patch,\n",
    "    \"patched_logits\": patched_logits,\n",
    "    \"patched_margin\" : l_diff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b3bd1bd-ba5b-43fb-addd-d132fa51b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_idx': 10, 'patched_logits': tensor([14.0625,  7.4375], device='cuda:0', dtype=torch.bfloat16), 'patched_margin': 6.625}\n"
     ]
    }
   ],
   "source": [
    "print(patch_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608bcc0-c58f-4279-a8b5-43a67a64ed57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
