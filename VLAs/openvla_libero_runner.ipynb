{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenVLA \u00d7 LIBERO robosuite demo (notebook)\n",
        "\n",
        "This notebook mirrors the `openvla_libero_runner.py` script but runs inside a cell-based workflow. It loads a LIBERO robosuite task, connects an OpenVLA checkpoint, and streams both an on-screen simulator window and off-screen camera frames for the policy. Make sure your environment is set up with the dependencies listed in `VLAs/readme.md` before running the cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Install-time environment notes\n",
        "# - robosuite with mujoco (with GUI support) and libero must be installed\n",
        "# - the `openvla` package and chosen checkpoint should be available\n",
        "# - this notebook expects GPU access by default but can be switched to CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import importlib.util\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import robosuite as suite\n",
        "from robosuite.wrappers import GymWrapper\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "Adjust these values to point at your preferred LIBERO benchmark, task index, and OpenVLA checkpoint. The `camera_name` controls both the on-screen viewer perspective and the off-screen images fed to the policy. Set `device` to `\"cpu\"` if you do not have a GPU available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "benchmark_name = \"libero_spatial\"  # e.g., libero_spatial, libero_object\n",
        "benchmark_task_index = 0\n",
        "model_id = \"openvla-openai/7b\"  # model identifier or local checkpoint directory\n",
        "camera_name = \"agentview\"\n",
        "horizon = 200\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "seed = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class LiberoTask:\n",
        "    \"\"\"Container for a single LIBERO task description.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    language_instruction: str\n",
        "    env_kwargs: Dict\n",
        "\n",
        "\n",
        "class LiberoBenchmark:\n",
        "    \"\"\"Light-weight adapter for LIBERO benchmarks.\n",
        "\n",
        "    The official ``libero`` package exposes benchmarks as Python dictionaries.\n",
        "    To avoid hard-coding every variant, we request the benchmark dynamically so\n",
        "    the notebook works for both spatial/object variants.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, benchmark_name: str):\n",
        "        if importlib.util.find_spec(\"libero\") is None:\n",
        "            raise ImportError(\n",
        "                \"The libero package is required for benchmark lookup. Install it with `pip install libero` \"\n",
        "                \"and ensure all robosuite extras are available.\"\n",
        "            )\n",
        "\n",
        "        from libero.benchmark import get_benchmark  # type: ignore\n",
        "\n",
        "        benchmark = get_benchmark(benchmark_name)\n",
        "        if benchmark is None:\n",
        "            raise ValueError(f\"Unknown LIBERO benchmark '{benchmark_name}'\")\n",
        "\n",
        "        self.tasks = [\n",
        "            LiberoTask(\n",
        "                name=task.name,\n",
        "                language_instruction=task.language,\n",
        "                env_kwargs=task.kwargs,\n",
        "            )\n",
        "            for task in benchmark.tasks\n",
        "        ]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tasks)\n",
        "\n",
        "    def __getitem__(self, index: int) -> LiberoTask:\n",
        "        return self.tasks[index]\n",
        "\n",
        "\n",
        "class OpenVLAPolicy:\n",
        "    \"\"\"Wrap an OpenVLA checkpoint to return continuous actions.\"\"\"\n",
        "\n",
        "    def __init__(self, model_id: str, device: str = \"cuda\"):\n",
        "        if importlib.util.find_spec(\"openvla\") is None:\n",
        "            raise ImportError(\n",
        "                \"The openvla package is required for inference. Install it via `pip install openvla` or \"\n",
        "                \"follow the official instructions to pull the model weights.\"\n",
        "            )\n",
        "\n",
        "        from openvla.modeling import load_pretrained_model  # type: ignore\n",
        "        from openvla.processing import OpenVLAProcessor  # type: ignore\n",
        "\n",
        "        self.device = device\n",
        "        self.model = load_pretrained_model(model_id).to(device)  # type: ignore[arg-type]\n",
        "        self.model.eval()\n",
        "        self.processor = OpenVLAProcessor.from_pretrained(model_id)  # type: ignore[call-arg]\n",
        "\n",
        "    def act(self, image: np.ndarray, proprio: np.ndarray, language: str) -> np.ndarray:\n",
        "        # robosuite returns images as HxWxC in uint8; OpenVLA expects PIL/torch.\n",
        "        inputs = self.processor(\n",
        "            images=image,\n",
        "            proprio=proprio.tolist(),\n",
        "            text=language,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model(**inputs)\n",
        "\n",
        "        # OpenVLA returns an action distribution; we take the mean.\n",
        "        action = output.action.squeeze(0).detach().cpu().numpy()\n",
        "        return action\n",
        "\n",
        "\n",
        "def make_env(task: LiberoTask, camera_name: str, horizon: int, seed: int) -> GymWrapper:\n",
        "    env = suite.make(\n",
        "        **task.env_kwargs,\n",
        "        has_renderer=True,  # pop up an interactive viewer\n",
        "        has_offscreen_renderer=True,\n",
        "        render_camera=camera_name,\n",
        "        use_camera_obs=True,\n",
        "        camera_names=[camera_name],\n",
        "        horizon=horizon,\n",
        "        control_freq=20,\n",
        "        reward_shaping=True,\n",
        "    )\n",
        "    env = GymWrapper(env, keys=[\"image\", \"robot-state\", \"task-obs\"])\n",
        "    env.reset()\n",
        "    env.env.seed(seed)\n",
        "\n",
        "    # Align the viewer with the requested camera if the backend supports it.\n",
        "    if getattr(env.env, \"viewer\", None) is not None:\n",
        "        try:\n",
        "            env.env.viewer.set_camera(camera_name)  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return env\n",
        "\n",
        "\n",
        "def run_episode(env: GymWrapper, policy: OpenVLAPolicy, task: LiberoTask, camera_name: str, render_gui: bool = True) -> float:\n",
        "    obs = env.reset()\n",
        "    cumulative_reward = 0.0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # update the on-screen viewer (if available)\n",
        "        if render_gui:\n",
        "            try:\n",
        "                env.render()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        image = env.sim.render(\n",
        "            camera_name=camera_name,\n",
        "            height=240,\n",
        "            width=320,\n",
        "            depth=False,\n",
        "        )\n",
        "        proprio = obs[\"robot-state\"]\n",
        "        action = policy.act(image=image, proprio=proprio, language=task.language_instruction)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        cumulative_reward += float(reward)\n",
        "\n",
        "    return cumulative_reward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load benchmark + policy\n",
        "This cell instantiates the LIBERO benchmark, builds the robosuite environment with an on-screen renderer, and loads the specified OpenVLA checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "benchmark = LiberoBenchmark(benchmark_name)\n",
        "if benchmark_task_index < 0 or benchmark_task_index >= len(benchmark):\n",
        "    raise IndexError(\n",
        "        f\"Task index {benchmark_task_index} is out of range for benchmark '{benchmark_name}' with {len(benchmark)} tasks\"\n",
        "    )\n",
        "\n",
        "libero_task = benchmark[benchmark_task_index]\n",
        "env = make_env(libero_task, camera_name=camera_name, horizon=horizon, seed=seed)\n",
        "policy = OpenVLAPolicy(model_id, device=device)\n",
        "\n",
        "print(f\"Loaded task '{libero_task.name}' with instruction: {libero_task.language_instruction}\")\n",
        "print(f\"Environment ready on device={device}; close the viewer window to stop the kernel if needed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run a single episode\n",
        "The loop below continuously renders the robosuite GUI window while capturing off-screen frames for OpenVLA. Close the viewer or interrupt the kernel to stop execution early.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "reward = run_episode(env, policy, libero_task, camera_name=camera_name, render_gui=True)\n",
        "print(f\"Finished task '{libero_task.name}' with reward {reward:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}