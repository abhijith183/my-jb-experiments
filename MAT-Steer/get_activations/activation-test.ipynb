{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43848a0-725d-48a2-87bd-67e638777cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c805fc-0541-4a6e-815f-1e453c6b8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0488f8a-772b-4ee9-b010-267d5a8c5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvene as pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ce212d-46f9-440a-8610-3ca6b97ab39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634055bc15b9496bb3c6f64e98e3f36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=\"./hf_cache\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype = torch.float16,\n",
    "    cache_dir=\"./hf_cache\",\n",
    "    low_cpu_mem_usage = True,\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b70e65b-5c0f-427b-a5ab-921666447d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cbb06f-d0e9-4fc6-975b-e994b17947ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_truthfulqa(question, choice):\n",
    "    return f\"Q: {question} A: {choice}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f64545-0e92-48de-9d4b-cf121accaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def load_task_dataset(dsname):\n",
    "    filepath = f\"{dsname}.json\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # print(data)\n",
    "    processed_data = []\n",
    "    for item in data[:20]:\n",
    "        question = item.get(\"question\", \"\")\n",
    "        choices = item.get(\"mc2_targets\",{}).keys()\n",
    "        # labels = item.get(\"mc2_targets\",{}).get(\"labels\", [])\n",
    "\n",
    "        # print(item.get(\"mc2_targets\",{}).keys())\n",
    "        # break\n",
    "        for choice in choices:\n",
    "            processed_data.append(\n",
    "                {\n",
    "                    \"text\": format_truthfulqa(question, choice),\n",
    "                    \"label\": int(item.get(\"mc2_targets\",{})[choice])\n",
    "                }\n",
    "            )\n",
    "            # print(processed_data)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7661f9f4-e60c-4d30-8d9d-2ef91a197786",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_task_dataset(\"mc_task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86221224-d728-4af8-8f58-fba54ec16d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "labels = []\n",
    "\n",
    "for item in dataset:\n",
    "    text = item[\"text\"]\n",
    "    label = item[\"label\"]\n",
    "    prompt = tokenizer(text, return_tensors='pt').input_ids\n",
    "    prompts.append(prompt)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a498b05-2531-4d34-baae-be2255333bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interveners import wrapper, Collector\n",
    "\n",
    "collectors = []\n",
    "\n",
    "pv_config = []\n",
    "\n",
    "for layer in range(model.config.num_hidden_layers): \n",
    "    collector = Collector(multiplier=0, head=-1) #head=-1 to collect all head activations, multiplier doens't matter\n",
    "    collectors.append(collector)\n",
    "    pv_config.append({\n",
    "        \"component\": f\"model.layers[{layer}].self_attn.o_proj.input\",\n",
    "        \"intervention\": wrapper(collector),\n",
    "    })\n",
    "collected_model = pv.IntervenableModel(pv_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93ea673-dd3b-409d-b574-64f2ad0459a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_wise_activations = []\n",
    "all_head_wise_activations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2badc6ba-7cbf-457a-bbce-36902dc22a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_activations_pyvene(collected_model, collectors, prompt, device):\n",
    "    with torch.no_grad():\n",
    "        prompt = prompt.to(device)\n",
    "        output = collected_model({\"input_ids\": prompt, \"output_hidden_states\": True})[1]\n",
    "    hidden_states = output.hidden_states\n",
    "    hidden_states = torch.stack(hidden_states, dim = 0).squeeze()\n",
    "    hidden_states = hidden_states.detach().cpu().numpy()\n",
    "    head_wise_hidden_states = []\n",
    "    for collector in collectors:\n",
    "        if collector.collect_state:\n",
    "            states_per_gen = torch.stack(collector.states, axis=0).cpu().numpy()\n",
    "            head_wise_hidden_states.append(states_per_gen)\n",
    "        else:\n",
    "            head_wise_hidden_states.append(None)\n",
    "        collector.reset()\n",
    "    mlp_wise_hidden_states = []\n",
    "    head_wise_hidden_states = torch.stack([torch.tensor(h) for h in head_wise_hidden_states], dim=0).squeeze().numpy()\n",
    "    return hidden_states, head_wise_hidden_states, mlp_wise_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4812fd88-beca-474a-8743-05e060b1aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 208/208 [00:14<00:00, 14.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# from utils import get_llama_activations_pyvene\n",
    "\n",
    "print(\"Getting activations\")\n",
    "for i, prompt in enumerate(tqdm(prompts)):\n",
    "    layer_wise_activations, head_wise_activations, _ = get_llama_activations_pyvene(collected_model, collectors, prompt, device)\n",
    "    # print(len(layer_wise_activations[0]), len(head_wise_activations))\n",
    "    # continue\n",
    "    # Extract only the last token activation from the specified layer\n",
    "    last_token_activation = layer_wise_activations[14, -1, :].copy()  # (D,)\n",
    "    all_layer_wise_activations.append(last_token_activation)\n",
    "    \n",
    "    # For head-wise, also extract only last token\n",
    "    last_token_head_activation = head_wise_activations[-1, :].copy()  # (H*d_head,)\n",
    "    all_head_wise_activations.append(last_token_head_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef75cad0-5f04-42d7-a13f-1ca8e8d6ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving labels\n",
      "Saving layer wise activations\n",
      "Saving head wise activations\n"
     ]
    }
   ],
   "source": [
    "all_layer_wise_activations = np.array(all_layer_wise_activations, dtype=np.float32)  # (N, D)\n",
    "all_head_wise_activations = np.array(all_head_wise_activations, dtype=np.float32)  # (N, H*d_head)\n",
    "labels = np.array(labels, dtype=np.int32)  # (N,)\n",
    "\n",
    "# Ensure features directory exists\n",
    "os.makedirs('../features', exist_ok=True)\n",
    "\n",
    "print(\"Saving labels\")\n",
    "np.save(f'../features/mistral_tqa_labels.npy', labels)\n",
    "\n",
    "print(\"Saving layer wise activations\")\n",
    "np.save(f'../features/mistral_tqa_layer_wise.npy', all_layer_wise_activations)\n",
    "\n",
    "print(\"Saving head wise activations\")\n",
    "np.save(f'../features/mistral_tqa_head_wise.npy', all_head_wise_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a96dba-c0fb-4a1d-ab02-85068db2fac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ff7f81-b0ba-4c69-b00b-db6717d752da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 4096)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layer_wise_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a948a5e-49e1-489a-a242-6a66ae273226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
